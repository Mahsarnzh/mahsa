{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"1_homework.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"executive-joyce"},"source":["# Homework 1\n","\n","The aim of this homework is to get familiar with norms and inner products, building blocks that we use to create a simple k-NN classifier.\n"],"id":"executive-joyce"},{"cell_type":"code","metadata":{"id":"respected-explorer","executionInfo":{"status":"ok","timestamp":1631903283975,"user_tz":240,"elapsed":104,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}}},"source":["import numpy as np"],"id":"respected-explorer","execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"productive-final"},"source":["## Exercise 1 - Implementing Norms\n","\n","We introduced norms as a way to measure the 'size' of a vector. Before we continue, recall the definition of the $p$-norms and the $\\infty$-norm. For a vector $x = (x_1,\\dots,x_n) \\in \\mathbb{R}^n$ and number $p\\geq 1$, the $p$-norm is given by \n","\n","\n","$$\n","\\|x\\|_p = \\left(\\sum_{i=1}^n |x_i|^p\\right)^{1/p} ,\n","$$\n","\n","and the $\\infty$-norm is given by\n","\n","$$\n","\\|x\\|_\\infty = \\max_{i=1,\\dots, n}|x_i| .\n","$$\n","\n","\n","Consider the following two vectors $\\mathbf{a}$ and $\\mathbf{b}$."],"id":"productive-final"},{"cell_type":"code","metadata":{"id":"capable-irish","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631904302014,"user_tz":240,"elapsed":108,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"655f23cd-c7eb-41ba-eeb2-0a7787e5d90d"},"source":["a = np.array([ 1.1, -0.4,  1.4,  0.7, -0.8, 1.1,  0.5, 0.0,  0.5,  1.6])\n","b = np.array([14.0,  4.1,  5.1 , -5.7, 15.6, 2.1, 11.0, -8.7, -6.7, -2.2])\n","print (a)"],"id":"capable-irish","execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 1.1 -0.4  1.4  0.7 -0.8  1.1  0.5  0.   0.5  1.6]\n"]}]},{"cell_type":"markdown","metadata":{"id":"academic-stopping"},"source":["NumPy provides a build-in routine to compute different norms of vectors. This routine is called `norm` and part of the `linalg` toolkit. In the following we use this routine to compute the $\\ell_2$, $\\ell_1$ and $\\ell_\\infty$ norm, that are special cases of the more general $p$-norm. \n","\n","* For more details have a look at the [NumPy documentation for norms](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n","\n","Let's start with the $\\ell_2$ of the vector $\\mathbf{a}$. (The 2-norm is the default norm, so you can also set `ord=None` which is the default.)"],"id":"academic-stopping"},{"cell_type":"code","metadata":{"id":"german-karen","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631907022965,"user_tz":240,"elapsed":74,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"7978c018-5720-41eb-b981-386ad335f4ea"},"source":["np.linalg.norm(b, ord=2)"],"id":"german-karen","execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27.667670664513842"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","metadata":{"id":"noted-howard"},"source":["Next, we compute the $\\ell_1$ norm."],"id":"noted-howard"},{"cell_type":"code","metadata":{"id":"ranging-pharmaceutical","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631907130876,"user_tz":240,"elapsed":79,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"de447d7f-dfc0-4539-b229-408fc946dfe9"},"source":["np.linalg.norm(b, ord=1)"],"id":"ranging-pharmaceutical","execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["75.2"]},"metadata":{},"execution_count":128}]},{"cell_type":"markdown","metadata":{"id":"reverse-property"},"source":["Finally, we compute the $\\ell_\\infty$ norm."],"id":"reverse-property"},{"cell_type":"code","metadata":{"id":"acceptable-camel","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631902691561,"user_tz":240,"elapsed":98,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"5ac84785-fecb-4e2e-b0e9-f4cf0381604c"},"source":["np.linalg.norm(a, ord=np.inf)"],"id":"acceptable-camel","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.6"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"encouraging-arrival"},"source":["You can also compute the distance between two vectors."],"id":"encouraging-arrival"},{"cell_type":"code","metadata":{"id":"collect-monitor","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631903510853,"user_tz":240,"elapsed":120,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"2d96130a-355a-4f0b-ab7b-b0b417e2bf54"},"source":["np.linalg.norm(a-b, ord=2)"],"id":"collect-monitor","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["27.631322805830344"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"respective-lemon"},"source":["## Part A (2 points)\n","\n","Now it is your turn. Implement these three norms using either a for-loop or better vectorized operations such as `np.sum` and check that your results are correct.\n","\n","Here goes your implementation of the the $\\ell_2$."],"id":"respective-lemon"},{"cell_type":"code","metadata":{"id":"technological-dakota","executionInfo":{"status":"ok","timestamp":1631907003629,"user_tz":240,"elapsed":75,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}}},"source":["def two_norm(a):\n","  a = np.sum(a[:]**2)\n","  return a**0.5"],"id":"technological-dakota","execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tObl2tWmIBhp","executionInfo":{"status":"ok","timestamp":1631906286046,"user_tz":240,"elapsed":79,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"6077183e-4e51-4abe-f006-a76b615ef0f8"},"source":["a = np.array([ 1.1, -0.4,  1.4,  0.7, -0.8, 1.1,  0.5, 0.0,  0.5,  1.6])\n","print(a[:]**2)\n","w = np.sum(a[:]**2)\n","print(w**0.5)"],"id":"tObl2tWmIBhp","execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.21 0.16 1.96 0.49 0.64 1.21 0.25 0.   0.25 2.56]\n","2.9546573405388314\n"]}]},{"cell_type":"code","metadata":{"id":"creative-sweden","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631907030777,"user_tz":240,"elapsed":74,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"6ef55440-bc2b-4553-c434-67fdd3f33cb9"},"source":["print(two_norm(b))"],"id":"creative-sweden","execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["27.667670664513846\n"]}]},{"cell_type":"markdown","metadata":{"id":"herbal-myrtle"},"source":["## Part B (2 points)\n","\n","Here goes your implementation of the the $\\ell_1$."],"id":"herbal-myrtle"},{"cell_type":"code","metadata":{"id":"dried-clock","executionInfo":{"status":"ok","timestamp":1631907390040,"user_tz":240,"elapsed":74,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}}},"source":["\n","def one_norm(a):\n","  c = np.sum(a)\n","  a=c//(len(a))\n","  return a"],"id":"dried-clock","execution_count":148,"outputs":[]},{"cell_type":"code","metadata":{"id":"sophisticated-lemon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631907392025,"user_tz":240,"elapsed":78,"user":{"displayName":"Mahsa Raeesinezhad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmYK0VDMN8YErFOLqHS8Gxbc55ABceZfaFccbCBg=s64","userId":"03658862156470047908"}},"outputId":"cd8f3d16-9f59-4346-ac0c-7ac4d27875ac"},"source":["print(one_norm(a))"],"id":"sophisticated-lemon","execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"documentary-activity"},"source":["## Part C (2 points)\n","\n","\n","Here goes your implementation of the the $\\ell_\\infty$."],"id":"documentary-activity"},{"cell_type":"code","metadata":{"id":"logical-browser"},"source":["def inf_norm(x):\n","    return # your code"],"id":"logical-browser","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"original-regard"},"source":["print(inf_norm(a))"],"id":"original-regard","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sorted-reaction"},"source":["## Part D (2 points)\n","\n","Use your function `two_norm` to compute the unit vector $\\mathbf{\\hat{b}}$, i.e., $\\|\\mathbf{\\hat{b}}\\|_2=1$."],"id":"sorted-reaction"},{"cell_type":"code","metadata":{"id":"square-marina"},"source":["b_hat = # your code"],"id":"square-marina","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"indirect-illustration"},"source":["print(b_hat)"],"id":"indirect-illustration","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"valued-split"},"source":["Check that $\\mathbf{\\hat{b}}$ has actually length 1."],"id":"valued-split"},{"cell_type":"code","metadata":{"id":"identical-cable"},"source":["print(np.linalg.norm(b_hat))"],"id":"identical-cable","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"talented-legislation"},"source":[""],"id":"talented-legislation","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unlimited-welcome"},"source":["# Optional: Lp Balls\n","\n","In the previous section, we introduced norms as a way to measure the 'size' of a vector. Here, we will see that norms give us a natural way to define an important type of set, namely balls associated with those norms. \n","These balls generalize circles and spheres (which are the balls associated with the Euclidean norm in $\\mathbb{R}^{2}$ and $\\mathbb{R}^{3}$, respectively.\n","They can be used to understand the hard-to-visualize $\\mathbb{R}^{n}$.\n","\n","\n","For any given $p$-norm, for $p \\in [1,\\infty]$, there is a special set called the _unit $p$-ball_, which is defined as\n","\n","$$\n","B_p = \\{x\\in\\mathbb{R}^n \\mid \\|x\\|_p \\leq 1\\}\n","$$\n","\n","This set contains all vectors $x\\in \\mathbb{R}^n$ whose $p$-norm is at most $1$. \n","The term 'ball' is used to describe this object because of intuition coming from the Euclidean norm / $2$-norm. \n","This will become more clear in the next section.\n","\n","\n","### The Euclidean ball\n","\n","A special case of the unit $p$-balls is the Euclidean unit ball, which is given by the set\n","\n","$$\n","B_2 = \\{x\\in\\mathbb{R}^n\\mid \\|x\\|_2 \\leq 1\\} .\n","$$\n","\n","To get some intuition, let's focus on the 2-dimensional case -- i.e., when $n=2$. \n","Then, the unit ball is the set of all points $x = (x_1,x_2)$ such that $\\sqrt{x_1^2 + x_2^2} \\leq 1$, or equivalently, the set of all points such that $x_1^2 + x_2^2 \\leq 1$. \n","From basic geometry, we know that the equation $x_1^2 + x_2^2 = 1$ defines a circle of radius 1 in the plane.\n","Hence, the set of points satisfying $x_1^2 + x_2^2 \\leq 1$ includes all points on or inside of this circle. \n","\n","To visualize the unit balls in this section, below we define the function `plotUnitBall()`, which plots the $p$-balls using the following method: first, we draw a point $x$ at random from the set $[-1,1]\\times[-1,1]$, and then plot the point if $\\|x\\|_p\\leq 1$, and don't plot it otherwise. \n","We repeat this for $5000$ points. However, you can also try varying the number of points yourself by changing the value of `n_samples`."],"id":"unlimited-welcome"},{"cell_type":"code","metadata":{"id":"corporate-companion"},"source":["import matplotlib.pyplot as plt\n","import numpy as np \n","from numpy.linalg import norm\n","def plotUnitBall(p, n_samples=5000):\n","    x_valid = []\n","    for i in range(n_samples):\n","        x = np.array([np.random.rand()*2-1,np.random.rand()*2-1]) #random point in [-1,1] x [-1,1]\n","        if norm(x,ord=p) <= 1:\n","            x_valid.append(x)\n","    x_valid = np.asarray(x_valid).T\n","    plt.scatter(x_valid[0,:],x_valid[1,:], color='blue')    \n","    plt.axis('square')\n","    title = 'Unit %s ball' % str(p)\n","    plt.title(title, fontsize=16)\n","    plt.xlim(-1.5, 1.5)\n","    plt.ylim(-1.5, 1.5)\n","    plt.show()"],"id":"corporate-companion","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"light-facing"},"source":["Visually, we can use this to verify that the set $B_2$ is indeed a circle:"],"id":"light-facing"},{"cell_type":"code","metadata":{"id":"educated-director"},"source":["plotUnitBall(2)"],"id":"educated-director","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"global-spread"},"source":["As expected, we see that this gives us a circle of radius of radius $1$. \n","\n","\n","### Visualizing the $1$-ball and $\\infty$-ball\n","\n","While the unit ball for the $2$-norm was in fact a 'round' ball shape, this is not the case for other norms. \n","Before plotting them, however, let's try to figure out what the shape of the $\\infty$ and $1$ norm balls should be. \n","\n","Let's start with the $\\infty$-norm ball. Take a point $x\\in [-1,1]\\times [-1,1]$. What is the largest that its $\\infty$-norm could be? We have $\\|x\\|_\\infty = \\max(|x_1|, |x_2|)$, but since $x_1 \\in [-1,1]$ and $x_2\\in [-1,1]$, we have that $|x_1|$ and $|x_2|$ are both at most $1$, hence $\\|x\\|_\\infty \\leq 1$. \n","On the other hand, if $x$ is outside of the set $[-1,1]\\times [-1,1]$, then at least one of its components is larger than $1$ in absolute value, and so its $\\infty$-norm must be greater than one. \n","Therefore we guess that the unit $\\infty$-ball must just be the entire box $[-1,1]\\times[-1,1]$. \n","\n","Let's test this out using the `plotUnitBall()` function."],"id":"global-spread"},{"cell_type":"code","metadata":{"id":"corresponding-samoa"},"source":["plotUnitBall(np.inf)"],"id":"corresponding-samoa","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"respiratory-darwin"},"source":["As expected, we get a box (with sides parallel to the canonical axes)!\n","\n","Now let's move on to the $1$-norm. Let's consider the points along the boundary of the $1$-norm ball, which are the points satisfying  $|x_1|+|x_2| = 1$. When $x_1, x_2\\geq 0$, this just gives us the equation of a line with slope $-1$ and intercept $1$: $x_2 = 1-x_1$. When $x_2\\geq 0$ and $x_1<0$, then this equation gives us a line with slope $1$ and intercept $1$: $x_2 = 1+x_1$. When $x_2<0$ and $x_1<0$, then we get a line with slope $-1$ and intercept $-1$: $x_2 = -1 - x_1$, and finally what $x_2<0$ and $x_1\\geq 0$, we get a line with slope $1$ and intercept $-1$: $x_2 = -1+x_1$. If we put these four lines together, we should get the shape of a diamond. \n","\n","Let's verify this with our `plotUnitBall()` function:"],"id":"respiratory-darwin"},{"cell_type":"code","metadata":{"id":"ruled-spelling"},"source":["plotUnitBall(1)"],"id":"ruled-spelling","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"listed-immigration"},"source":["### Comparing unit balls of different norms\n","\n","In the last section in the workbook, we saw that the $p$-norms are ordered, meaning that if $1\\leq p<q\\leq \\infty$, then for any vector $x$\n","\n","$$\n","\\|x\\|_q \\leq \\|x\\|_p  .\n","$$\n","\n","What does this mean in terms of the sizes of the different unit balls? \n","Intuitively, if the norm $\\|\\cdot\\|_q$ gives _smaller_ values than $\\|\\cdot\\|_p$, then _more_ vectors will have norm $\\leq 1$ with respect to the $q$-ball than the $p$-ball. \n","Hence, because of the above inequality, we expect the unit balls to get bigger as $p$ grows. \n","Indeed, the $\\infty$-norm ball is the largest of all the unit balls, and the $1$-ball is the smallest. \n","A natural way to measure the size of the unit balls (at least in $\\mathbb{R}^2$) is to measure their area (or volume, for $\\mathbb{R}^{n}$, for $n \\ge 3$). \n","For example, the $\\infty$-ball is just the entire set $[-1,1]\\times[-1,1]$, which is a box with area $4$, and the $2$-ball is a circle with radius $1$, which has area $\\pi$. \n","\n","We include a function below which lets us estimate the area of any $p$-ball."],"id":"listed-immigration"},{"cell_type":"code","metadata":{"id":"institutional-river"},"source":["def unitBallVolume(p, n_samples=10000):\n","    vol = 0\n","    for i in range(n_samples):\n","        x = np.array([np.random.rand()*2-1,np.random.rand()*2-1]) #random point in [-1,1] x [-1,1]\n","        if norm(x,ord=p) <= 1:\n","            vol += 1\n","    vol /= n_samples\n","    vol *= 4\n","    return vol"],"id":"institutional-river","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frank-contractor"},"source":["The function `unitBallVolume(p)` works in the following way: similar to how we plotted the unit balls, we sample `n_samples` (defaulting to 10,000) points at random from the set $[-1,1]\\times[-1,1]$ and measure the fraction of points that satisfy $\\|x\\|_p\\leq 1$. \n","We then mulitply the result by $4$ (the area of the box $[-1,1]\\times[-1,1]$), and this gives us a pretty good estimate of the area of unit $p$-ball! \n","Let's check this with the $2$-ball, and see if it gives us a good approximation to $\\pi$:"],"id":"frank-contractor"},{"cell_type":"code","metadata":{"id":"aquatic-pricing"},"source":["unitBallVolume(2)"],"id":"aquatic-pricing","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"later-formation"},"source":["This will give us a different result every time due to random sampling, but it should be a pretty good estimate. We can make the approximation better by increasing the value of `n_samples`. \n","\n","We can do a similar check with the $1$-ball. \n","This area can be computed by recognizing that the diamond shape is made up of 4 right triangles, each with area $1/2$, and so the area of the unit $1$-ball should be $2$. \n","Let's check that our function gives us a reasonably accurate estimate:"],"id":"later-formation"},{"cell_type":"code","metadata":{"id":"victorian-stamp"},"source":["unitBallVolume(1)"],"id":"victorian-stamp","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"unauthorized-shooting"},"source":["Note that this function just computes things in $\\mathbb{R}^2$, but in principal we could apply the same method to estimate the _volumes_ of the $p$-balls in any dimension -- though the computation would in general be much slower. \n","\n","Now we can use this function to see how the area of the unit balls in 2 dimensions grows with $p$:"],"id":"unauthorized-shooting"},{"cell_type":"code","metadata":{"id":"favorite-possession"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","p_range = np.arange(1, 20, 1)\n","areas = [unitBallVolume(p) for p in p_range]\n","\n","plt.plot(p_range, areas)\n","plt.xlabel('p', fontsize=14)\n","plt.ylabel('area of p-ball', fontsize=14)\n","plt.show()"],"id":"favorite-possession","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"future-peace"},"source":["As expected, this is a nice increasing curve which starts at $2$ (the area of the 1-ball) and increases to very close to $4$ (the area of the $\\infty$-ball)."],"id":"future-peace"},{"cell_type":"markdown","metadata":{"id":"smart-pathology"},"source":["## Exercise 2 - Implementing Dot Products\n","\n","### Review of dot products in $\\mathbb{R}^n$\n","\n","One of the most important quantities we compute in linear algebra are _inner products_, also called the _dot product_. \n","For two vectors $x,y \\in \\mathbb{R}^n$, the inner product is the number\n","\n","\n","$$\n","x^\\top y = \\sum_{i=1}^n x_iy_i .\n","$$\n","\n","\n","Importantly, an inner product can be thought of as a linear function from $\\mathbb{R}^n$ to $\\mathbb{R}$: if we fix $y\\in \\mathbb{R}^n$, then the function $T_y(x) = x^\\top y$ is clearly linear, since for any $x,x' \\in \\mathbb{R}^n$ and $\\alpha \\in \\mathbb{R}$, we have\n","\n","\n","$$\n","T_y(x + \\alpha x') = (x+\\alpha x')^\\top y = \\sum_{i=1}^n (x_i + \\alpha x'_i)y_i = \\sum_{i=1}^n x_iy_i + \\alpha\\sum_{i=1}^nx'_iy_i = x^\\top y + \\alpha (x')^\\top y = T_y(x) + \\alpha T_y(x') .\n","$$\n","\n","\n","Dot products are also the basis of matrix multiplication: if $A \\in \\mathbb{R}^{n\\times m}$ and $B\\in \\mathbb{R}^{m\\times p}$ are matrices, and $a_1,\\dots, a_n$ are the rows of $A$ and $b_1,\\dots, b_p$ are the columns of $B$, then the $(i,j)$th element of $AB$ is just $a_i^\\top b_j$. \n","\n","In this chapter, however, we will be interested in a more geometric interpretation of dot products, namely that they are used to compute the angle between two vectors.\n","\n","### Computing angles between vectors with dot products\n","\n","One of the most important facts about dot products is that they give us a way to compute the _angle_ $\\theta$ between any two vectors $x,y\\in \\mathbb{R}^n$. \n","This is due to the following important identity:\n","\n","\n","$$\n","x^\\top y = \\|x\\|_2\\|y\\|_2\\cos(\\theta)\n","$$\n","\n","\n","Therefore we have that the angle $\\theta$ can be found with \n","\n","\n","$$\n","\\theta = \\arccos \\left(\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}\\right)\n","$$\n","\n","\n","\n","To compute a dot product between two vectors in python, you can use the the routine `np.dot`, or you can also use the method `.dot`. \n","\n","Let's compute the dot product of $\\mathbf{a}$ and $\\mathbf{b}$."],"id":"smart-pathology"},{"cell_type":"code","metadata":{"id":"magnetic-fountain"},"source":["a.dot(b)"],"id":"magnetic-fountain","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"homeless-qatar"},"source":["np.dot(a,b)"],"id":"homeless-qatar","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"colored-lafayette"},"source":["There is also a third way to compute the dot product between two vectors."],"id":"colored-lafayette"},{"cell_type":"code","metadata":{"id":"brutal-volunteer"},"source":["a @ b"],"id":"brutal-volunteer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bronze-sociology"},"source":["## Part A (4 points)\n","\n","\n","To build some more intuition, implement first a for loop to compute the dot product, and then use the `np.sum` routine to implement the dot product."],"id":"bronze-sociology"},{"cell_type":"code","metadata":{"id":"compound-birmingham"},"source":["def dot_product_loop(x,y):\n","    # your code\n","    # your code\n","    return # your code"],"id":"compound-birmingham","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"exciting-apple"},"source":["def dot_product(x,y):\n","    return # your code"],"id":"exciting-apple","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"primary-singing"},"source":["Let's check that your two functions are correct."],"id":"primary-singing"},{"cell_type":"code","metadata":{"id":"simple-blank"},"source":["dot_product_loop(a,b)"],"id":"simple-blank","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"driven-lesson"},"source":["dot_product(a,b)"],"id":"driven-lesson","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"certified-camel"},"source":["You should yield the same results as given by the build in NumPy functions.\n","\n","While for loops are often useful, they are slow. Let's compare the computational speed between the build-in function and the two functions that you just coded. First, we create two random vector of length $10.000.000$."],"id":"certified-camel"},{"cell_type":"code","metadata":{"id":"cross-breath"},"source":["np.random.seed(1)\n","p = np.random.standard_normal(10**7)\n","q = np.random.standard_normal(10**7)"],"id":"cross-breath","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"express-possession"},"source":["%%time\n","print(p.dot(q))"],"id":"express-possession","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"conscious-collins"},"source":["%%time\n","print(dot_product_loop(p,q))"],"id":"conscious-collins","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pregnant-tunisia"},"source":["%%time\n","print(dot_product(p,q))"],"id":"pregnant-tunisia","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"romance-eclipse"},"source":["You should see that the in-build dot product takes only a few milliseconds, while the loop takes a few seconds. On my machine the in-build machine is faster by a factor of about 400!"],"id":"romance-eclipse"},{"cell_type":"markdown","metadata":{"id":"boxed-brazilian"},"source":["# Exercise - Cosine Similarity\n","\n","Text mining and classification problems play a vital role in many real world applications. For example, assume you are asked to categorize a few hundred news paper articles based on the headlines. Of course, you can do this job by hand, but it might be tedious. So let's think about how we can automate this task. \n","\n","Assume you are given the following headlines. \n","\n","* Tomorrow will be a rainy day! \n","* It will be a rainy day tomorrow!\n","* Deep learning algorithm finds hidden warning!\n","* Machine learning is able to learn without human supervision!\n","\n","You can guess that the first and second headline belong to same category, i.e., weather. In order to come up with a quantitative answer, we need to first transform each of these text sequences into a set of ordered numeric values. There are many ways to do so, and a simple method is to count the appearance of each word in the text sequence. First, we need to store the text sequences as strings in a list. "],"id":"boxed-brazilian"},{"cell_type":"code","metadata":{"id":"acceptable-contract"},"source":["headlines = [\n","'linear algebra can do fun things', \n","'I can do fun things with linear algebra',\n","'machine learning is the future',\n","'deep learning is even more fun'\n","]"],"id":"acceptable-contract","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"threaded-chick"},"source":["Now, we can use a function provided by scikit-learn to transform the raw text into a matrix."],"id":"threaded-chick"},{"cell_type":"code","metadata":{"id":"preceding-stockholm"},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer = CountVectorizer()\n","sentence_vectors = vectorizer.fit_transform(headlines)\n","X = sentence_vectors.toarray()\n","print(X)"],"id":"preceding-stockholm","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"level-fraud"},"source":["Looking at the rows, you can tell that the first and second row look very similar. To get a numeric answer, we can compute the cosine similarity between the first and second row of the matrix, i.e., between two vectors. \n","\n","Recall, cosine similarity is a metric that measures how similar or dissimilar two vectors are is defined as\n","\n","$$ \t\\text{similarity}(\\boldsymbol{x},\\boldsymbol{y}) := \\cos \\theta= \\frac{\\boldsymbol{x}^T \\boldsymbol{y}}{\\|\\boldsymbol{x}\\|_2 \\|\\boldsymbol{y}\\|_2} $$\n","\n","We can use a build in function in Sklearn to do so."],"id":"level-fraud"},{"cell_type":"code","metadata":{"id":"valued-headquarters"},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","print(cosine_similarity(X[0].reshape(1, -1), X[1].reshape(1, -1))[0])"],"id":"valued-headquarters","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"warming-median"},"source":["## Part A (2 points)\n","\n","\n","Now, write your own function that computes cosine similarity using only numpy's dot product. \n","\n","Recall that you can compute the 2-norm of a vector as $\\|\\mathbf{x}\\|_2 = \\sqrt{\\mathbf{x}^T \\mathbf{x}}$. "],"id":"warming-median"},{"cell_type":"code","metadata":{"id":"accredited-mailing"},"source":["def cos_similarity(x, y):\n","    return # your code"],"id":"accredited-mailing","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"overall-hammer"},"source":["print(cos_similarity(X[0], X[1]))"],"id":"overall-hammer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"transparent-devil"},"source":["Now, try to compute the cosine similarity between the first and third row. Did you expect this result?"],"id":"transparent-devil"},{"cell_type":"code","metadata":{"id":"brief-satisfaction"},"source":["print(cos_similarity(X[0], X[2]))"],"id":"brief-satisfaction","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fitting-clearing"},"source":["### A gotcha\n","\n","One point which is important to keep in mind when computing angles numerically is that we need to be careful when applying the $\\arccos$ function in practice. To meaningfully interpret the angle $\\arccos \\left(\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}\\right)$, we need to have that $-1\\leq \\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2} \\leq 1$. This is always true mathematically; however, numerically we could run into situations where $x$ and $y$ are parallel, but when we compute $\\frac{x^\\top y}{\\|x\\|_2 \\|y\\|_2}$ we obtain a number like $1.0000000000000002$. In this case, when we take the arccosine, we won't get a meaningful answer (since it is only defined for values in $[-1,1]$. Let's see a simple example."],"id":"fitting-clearing"},{"cell_type":"code","metadata":{"id":"acoustic-travel"},"source":["np.random.seed(1) #set seed for reproducibility\n","\n","a = np.random.randn(200)\n","b = 0.22342323423442342342342342343422342342343242342343234**2*a\n","print(cos_similarity(a, b))\n","print(np.arccos(cos_similarity(a, b)))"],"id":"acoustic-travel","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"decreased-adoption"},"source":["# k-Nearest Neighbors for Classifier\n","\n","In the following we aim to build our own k-Nearest Neighbors (kNN) Classifier and compare the performance to sklearn's kNN classifier routine. \n","\n","To experiment with our classifier we use the MNIST dataset. This dataset consists handwritten digits.\n"],"id":"decreased-adoption"},{"cell_type":"markdown","metadata":{"id":"tender-republican"},"source":["### The Dataset"],"id":"tender-republican"},{"cell_type":"markdown","metadata":{"id":"laden-person"},"source":["We load and visualize the first 25 hand-written digits in the dataset:"],"id":"laden-person"},{"cell_type":"code","metadata":{"id":"altered-preference"},"source":["from sklearn.datasets import load_digits\n","digits, targets = load_digits(return_X_y=True)"],"id":"altered-preference","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"comprehensive-lounge"},"source":["import matplotlib.pyplot as plt\n","\n","# set up the figure\n","fig, ax = plt.subplots(7,7,figsize=(10,8))\n","ax = ax.flatten()\n","\n","index = 0\n","for axis in ax:\n","    axis.imshow(digits[index,:].reshape(8,8), cmap=plt.cm.gray, interpolation='bicubic')\n","    axis.text(-2, 7, str(int(targets[index])))\n","    axis.axis('off')\n","    index +=1\n","plt.show()"],"id":"comprehensive-lounge","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"several-scholar"},"source":["The data consists of 8Ã—8 pixel images, meaning that they are 64-dimensional. Note, that this dataset is only a small subset of the MNIST database: http://yann.lecun.com/exdb/mnist/index.html.\n","\n","We can also plot some examples in vectorized form."],"id":"several-scholar"},{"cell_type":"code","metadata":{"id":"second-courage"},"source":["# set up the figure\n","fig, ax = plt.subplots(7,1,figsize=(10,8))\n","ax = ax.flatten()\n","\n","index = 0\n","for axis in ax:\n","    axis.imshow(digits[index,:].reshape(1,64), cmap=plt.cm.gray, interpolation='bicubic')\n","    axis.text(-2, 0, str(int(targets[index])))\n","    axis.axis('off')\n","    index +=1\n","plt.show()"],"id":"second-courage","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"generic-opera"},"source":["## Split the Dataset\n","\n","Next, we split the dataset into a training and test dataset."],"id":"generic-opera"},{"cell_type":"code","metadata":{"id":"approximate-helena"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(digits, targets, test_size=0.5, random_state=42)"],"id":"approximate-helena","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ongoing-tissue"},"source":["# Establish a Baseline using sklearn\n","\n","Before we build our own classifier, we establish a baseline using sklearn's k-NN classifier."],"id":"ongoing-tissue"},{"cell_type":"code","metadata":{"id":"excellent-cornell"},"source":["from sklearn.neighbors import KNeighborsClassifier"],"id":"excellent-cornell","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"continental-walnut"},"source":["First, we construct an object. For now, we set number of nearest neighbors to 1. "],"id":"continental-walnut"},{"cell_type":"code","metadata":{"id":"junior-irish"},"source":["neigh = KNeighborsClassifier(n_neighbors=1)"],"id":"junior-irish","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"prepared-grade"},"source":["Next, we fit the classifier to our data."],"id":"prepared-grade"},{"cell_type":"code","metadata":{"id":"fluid-information"},"source":["neigh.fit(X_train, y_train)"],"id":"fluid-information","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"honest-committee"},"source":["Now, we can check how accurate the classifier is. Therefore we first predict the labels for the data points in our test set and then we compute the accuracy, given that we know the true labels."],"id":"honest-committee"},{"cell_type":"code","metadata":{"id":"geographic-elite"},"source":["pred = neigh.predict(X_test)"],"id":"geographic-elite","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hearing-discipline"},"source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, pred)"],"id":"hearing-discipline","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"minute-encounter"},"source":["Wow! We got about 98.3% of all data points in our test set correct. "],"id":"minute-encounter"},{"cell_type":"markdown","metadata":{"id":"underlying-labor"},"source":["## Part A (5 points) - Build a Nearest Neighbor classifier from scratch"],"id":"underlying-labor"},{"cell_type":"markdown","metadata":{"id":"found-value"},"source":["Let's start with building a nearest neighbor classifier (i.e., k=1)."],"id":"found-value"},{"cell_type":"code","metadata":{"id":"narrative-indonesia"},"source":["class knn():\n","    def __init__(self, n_neighbors=1):\n","        self.n_neighbors = n_neighbors\n","        \n","    def fit(self, X, y):\n","        self.X = X\n","        self.y = y\n","        \n","    def predict(self, z):\n","        prediction = []\n","        for i in range(z.shape[0]):\n","            smallest_distance = np.inf\n","            predicted_class = None\n","            for j in range(self.X.shape[0]):\n","                distance = # your code\n","                if distance < smallest_distance:\n","                    smallest_distance = # your code\n","                    predicted_class = # your code\n","            prediction.append(predicted_class)\n","        return np.asarray(prediction) "],"id":"narrative-indonesia","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"attached-gravity"},"source":["my_knn = knn()"],"id":"attached-gravity","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"referenced-consensus"},"source":["my_knn.fit(X_train, y_train)"],"id":"referenced-consensus","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"outstanding-worthy"},"source":["pred = my_knn.predict(X_test)"],"id":"outstanding-worthy","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"relative-championship"},"source":["You should get the same answer as the sklearn knn classifier, i.e., 0.98."],"id":"relative-championship"},{"cell_type":"code","metadata":{"id":"initial-extraction"},"source":["accuracy_score(y_test, pred)"],"id":"initial-extraction","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"backed-thesis"},"source":["## Part B (5 points) - Build a k Nearest Neighbor classifier from scratch\n","\n","Let's extend the algorithm and build a k-NN classifier. One way to do is the following approach:\n","\n","* First compute all distances and store them in a list. \n","* Once we have computed the distances, we can convert the list into an `np.array` using `np.asarray`. \n","* Then, we can use `np.argsort` do find the index set that correspond to the data points in ascending.\n","* We can then use the index set to sort the targets `y`.\n","* Finally we select the k targets corresponding to the data points that are nearest to the query point. We can use the `mode` to compute the majority vote. Here is an example. Given a vector y, we compute the value that most often occurs as"],"id":"backed-thesis"},{"cell_type":"code","metadata":{"id":"absolute-instrument"},"source":["y = np.array([1,1,2,2,2,3,4,4,5,6,8,8,9])\n","np.bincount(y).argmax()"],"id":"absolute-instrument","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"august-release"},"source":["Here goes your code. "],"id":"august-release"},{"cell_type":"code","metadata":{"id":"little-soccer"},"source":["class knn():\n","    def __init__(self, n_neighbors=1):\n","        self.n_neighbors = n_neighbors\n","        \n","    def fit(self, X, y):\n","        self.X = X\n","        self.y = y\n","        \n","    def predict(self, z):\n","        prediction = []\n","        for i in range(z.shape[0]):\n","            distances = []\n","            for j in range(self.X.shape[0]):\n","                distance = # your code\n","                distances.append(distance)\n","            distances = np.asarray(distances)\n","            idx = # your code --- hint use np.argsort\n","            y_hat = # your code\n","            prediction.append(y_hat)\n","        return np.asarray(prediction) "],"id":"little-soccer","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rough-marble"},"source":["First try to compute the accuracy for k=1. You should get the same answer as before."],"id":"rough-marble"},{"cell_type":"code","metadata":{"id":"powerful-reggae"},"source":["my_knn = knn(n_neighbors=1)"],"id":"powerful-reggae","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"correct-frank"},"source":["my_knn.fit(X_train, y_train)"],"id":"correct-frank","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thorough-wrong"},"source":["pred = my_knn.predict(X_test)"],"id":"thorough-wrong","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"liked-project"},"source":["accuracy_score(y_test, pred)"],"id":"liked-project","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mobile-trademark"},"source":["Now, evaluate the your classifier for k in 1,2,3,...,15 and plot the test accuracy as a function of k."],"id":"mobile-trademark"},{"cell_type":"code","metadata":{"id":"forced-synthetic"},"source":["import timeit"],"id":"forced-synthetic","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"optimum-telling"},"source":["t0 = timeit.default_timer()\n","errors = []\n","for k in range(1,16):\n","    my_knn = knn(n_neighbors=k)\n","    my_knn.fit(X_train, y_train)\n","    pred = my_knn.predict(X_test)\n","    errors.append(accuracy_score(y_test, pred))\n","\n","print('Total time', timeit.default_timer()-t0)"],"id":"optimum-telling","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"efficient-binary"},"source":["plt.figure(figsize=(12,6))\n","plt.plot(range(1,16), errors, 'o--', c='red')\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.locator_params(axis='y', nbins=8)         \n","#plt.ylim(30, 98)\n","plt.ylabel('accuracy',fontsize=24)\n","plt.xlabel('number of nearest neighbor, k', fontsize=24)\n","plt.tight_layout()\n","plt.show()"],"id":"efficient-binary","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"demonstrated-balloon"},"source":[""],"id":"demonstrated-balloon","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"molecular-rhythm"},"source":["## Part C (3 points) - Vectorize the inner for loop\n","\n","The implementation that we have used is relatively slow. We don't need the inner for loop. Vectorize the code. You should see a speedup of a factor of about 30-40."],"id":"molecular-rhythm"},{"cell_type":"code","metadata":{"id":"skilled-poster"},"source":["class knn():\n","    def __init__(self, n_neighbors=1):\n","        self.n_neighbors = n_neighbors\n","        \n","    def fit(self, X, y):\n","        self.X = X\n","        self.y = y\n","        \n","    def predict(self, z):\n","        prediction = []\n","        for i in range(z.shape[0]):\n","            # your code\n","            # your code\n","            # your code\n","        return np.asarray(prediction) "],"id":"skilled-poster","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cathedral-species"},"source":["t0 = timeit.default_timer()\n","errors = []\n","for k in range(1,16):\n","    my_knn = knn(n_neighbors=k)\n","    my_knn.fit(X_train, y_train)\n","    pred = my_knn.predict(X_test)\n","    errors.append(accuracy_score(y_test, pred)) \n","print('Total time', timeit.default_timer()-t0)"],"id":"cathedral-species","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"female-mattress"},"source":["plt.figure(figsize=(12,6))\n","plt.plot(range(1,16), errors, 'o--', c='red')\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.locator_params(axis='y', nbins=8)         \n","#plt.ylim(30, 98)\n","plt.ylabel('accuracy',fontsize=24)\n","plt.xlabel('number of nearest neighbor, k', fontsize=24)\n","plt.tight_layout()\n","plt.show()"],"id":"female-mattress","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"growing-omega"},"source":[""],"id":"growing-omega","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"standing-color"},"source":["# k-Nearest Neighbors for Regression\n","\n","In the following we aim to build our own k-Nearest Neighbors (kNN) algorithm for regression problems. \n","\n","To experiment with our method we use the following artificial dataset."],"id":"standing-color"},{"cell_type":"code","metadata":{"id":"parliamentary-prize"},"source":["np.random.seed(1)\n","x = np.random.uniform(0,1, 200) * 9 \n","y = np.sin(x)  + x**0.5 + np.random.standard_normal(x.shape) *0.2\n","x = np.hstack((x, 5, 3, 8, 6))\n","y = np.hstack((y, 4, 3.5, 1, 0.1))\n","\n","plt.figure(figsize=(12,6))\n","plt.scatter(x,y, c='red')\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.ylabel('y',fontsize=24)\n","plt.xlabel('x', fontsize=24)\n","plt.tight_layout()\n","plt.show()   "],"id":"parliamentary-prize","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"republican-conflict"},"source":["## Split the Dataset\n","\n","Next, we split the dataset into a training and test dataset."],"id":"republican-conflict"},{"cell_type":"code","metadata":{"id":"patent-bleeding"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"],"id":"patent-bleeding","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"engaged-aquatic"},"source":["## Part A - Modify your k-NN class for Regression task (5 points)\n","\n","Provide an argument `weight` that allows the user to chose between the average and median metric for forming a vote / prediction.  "],"id":"engaged-aquatic"},{"cell_type":"code","metadata":{"id":"automatic-maryland"},"source":["class knnRegressor():\n","    def __init__(self, n_neighbors=1, weight='average'):\n","        self.n_neighbors = n_neighbors\n","        self.weight = weight\n","        \n","    def fit(self, X, y):\n","        self.X = X\n","        self.y = y\n","        \n","    def predict(self, z):\n","        prediction = []\n","        for i in range(z.shape[0]):\n","            distances = []\n","            for j in range(self.X.shape[0]):\n","                distance = # your code\n","                distances.append(distance)\n","            distances = np.asarray(distances)\n","            idx = np.argsort(distances)\n","            if self.weight == 'average':\n","                y_hat = # your code\n","                prediction.append(y_hat)\n","            elif self.weight == 'median':\n","                y_hat = # your code\n","                prediction.append(y_hat)\n","            \n","        return np.asarray(prediction) \n","    "],"id":"automatic-maryland","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"south-zoning"},"source":["Now, evaluate your model for different $k$s. Since this is a regression problem, we need a different measure to evaluate the predictive performance. We use the mean squared error (MSE) here that is defined as \n","\n","$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i-\\hat{y_i})^2$$\n"],"id":"south-zoning"},{"cell_type":"code","metadata":{"id":"framed-annotation"},"source":["from sklearn.metrics import mean_squared_error"],"id":"framed-annotation","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"immune-diesel"},"source":["t0 = timeit.default_timer()\n","errors = []\n","for k in range(1,16):\n","    my_knn = knnRegressor(n_neighbors=k, weight='average')\n","    my_knn.fit(X_train, y_train)\n","    pred = my_knn.predict(X_test)\n","    errors.append(mean_squared_error(y_test, pred)) \n","print('Total time', timeit.default_timer()-t0)"],"id":"immune-diesel","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"refined-respect"},"source":["plt.figure(figsize=(12,6))\n","plt.plot(range(1,16), errors, 'o--', c='red')\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.locator_params(axis='y', nbins=8)         \n","plt.ylabel('mean squared error',fontsize=24)\n","plt.xlabel('number of nearest neighbor, k', fontsize=24)\n","plt.tight_layout()\n","plt.show()"],"id":"refined-respect","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"written-backing"},"source":["print('MSE %s, for k=%s' %(np.min(errors), np.asarray(errors).argmin()+1 ))"],"id":"written-backing","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"primary-concentrate"},"source":["We see that we yield the best performance with about $k=13$.\n","\n","Now, let's repeat the experiment with the median for forming the vote."],"id":"primary-concentrate"},{"cell_type":"code","metadata":{"id":"offensive-treatment"},"source":["t0 = timeit.default_timer()\n","errors = []\n","for k in range(1,16):\n","    my_knn = knnRegressor(n_neighbors=k, weight='median')\n","    my_knn.fit(X_train, y_train)\n","    pred = my_knn.predict(X_test)\n","    errors.append(mean_squared_error(y_test, pred)) \n","print('Total time', timeit.default_timer()-t0)"],"id":"offensive-treatment","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"earlier-treasury"},"source":["plt.figure(figsize=(12,6))\n","plt.plot(range(1,16), errors, 'o--', c='red')\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.locator_params(axis='y', nbins=8)         \n","#plt.ylim(30, 98)\n","plt.ylabel('mean squared error',fontsize=24)\n","plt.xlabel('number of nearest neighbor, k', fontsize=24)\n","plt.tight_layout()\n","plt.show()"],"id":"earlier-treasury","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nervous-button"},"source":["print('MSE %s, for k=%s' %(np.min(errors), np.asarray(errors).argmin()+1 ))"],"id":"nervous-button","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"paperback-constant"},"source":["# Part B - Scatter Plot Smoother (optional)\n","\n","Okay, we see that the the MSE is smaller when using the median. That is because our training set has some outliers. To see this, fit a scatter plot smoother to the training data."],"id":"paperback-constant"},{"cell_type":"code","metadata":{"id":"exceptional-theorem"},"source":["my_knn = knnRegressor(n_neighbors=1, weight='average')\n","my_knn.fit(X_train, y_train)\n","pred = my_knn.predict(np.sort(X_train))\n","plt.figure(figsize=(12,6))\n","plt.scatter(x,y, c='red')\n","plt.plot(np.sort(X_train),pred, lw=3)\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.ylabel('y',fontsize=24)\n","plt.xlabel('x', fontsize=24)\n","plt.title('k=1',fontsize=24)\n","plt.tight_layout()\n","plt.show()   "],"id":"exceptional-theorem","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"finished-december"},"source":["my_knn = knnRegressor(n_neighbors=3, weight='average')\n","my_knn.fit(X_train, y_train)\n","pred = my_knn.predict(np.sort(X_train))\n","plt.figure(figsize=(12,6))\n","plt.scatter(x,y, c='red')\n","plt.plot(np.sort(X_train),pred, lw=3)\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.ylabel('y',fontsize=24)\n","plt.xlabel('x', fontsize=24)\n","plt.title('k=3',fontsize=24)\n","plt.tight_layout()\n","plt.show()  "],"id":"finished-december","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sorted-bridge"},"source":["Clearly we can see that the the outliers have a high influence here. If we chose $k=13$ then we have introduced enough regularization to mitigate the effect."],"id":"sorted-bridge"},{"cell_type":"code","metadata":{"id":"painted-makeup"},"source":["my_knn = knnRegressor(n_neighbors=13, weight='average')\n","my_knn.fit(X_train, y_train)\n","pred = my_knn.predict(np.sort(X_train))\n","plt.figure(figsize=(12,6))\n","plt.scatter(x,y, c='red')\n","plt.plot(np.sort(X_train),pred, lw=3)\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.ylabel('y',fontsize=24)\n","plt.xlabel('x', fontsize=24)\n","plt.title('k=12',fontsize=24)\n","plt.tight_layout()\n","plt.show()  "],"id":"painted-makeup","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"understood-hopkins"},"source":["Now, compare to the model using the median."],"id":"understood-hopkins"},{"cell_type":"code","metadata":{"id":"consistent-paraguay"},"source":["my_knn = knnRegressor(n_neighbors=3, weight='median')\n","my_knn.fit(X_train, y_train)\n","pred = my_knn.predict(np.sort(X_train))\n","plt.figure(figsize=(12,6))\n","plt.scatter(x,y, c='red')\n","plt.plot(np.sort(X_train),pred, lw=3)\n","plt.tick_params(axis='y', labelsize=24) \n","plt.tick_params(axis='x', labelsize=24) \n","plt.ylabel('y',fontsize=24)\n","plt.xlabel('x', fontsize=24)\n","plt.title('k=3',fontsize=24)\n","plt.tight_layout()\n","plt.show()  "],"id":"consistent-paraguay","execution_count":null,"outputs":[]}]}